{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnu-m77/Canadian-Tech-Internships-2023/blob/main/Metaculus_Bot_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Forecasting Bot Template\n",
        "\n",
        "\n",
        "This is a simple bot template that you can use to forecast in the Metaculus AI Benchmarking Warmup Contest. It is a single shot GPT prompt that you are encouraged to experiment with!\n",
        "\n",
        "In order to run this notebook as is, you'll need to enter a few API keys (use the key icon on the left to input them):\n",
        "\n",
        "- `METACULUS_TOKEN`: you can find your Metaculus token under your bot's user settings page: https://www.metaculus.com/accounts/settings/, or on the bot registration page where you created the account: https://www.metaculus.com/aib/\n",
        "- `OPENAPI_API_KEY`: get one from OpenAIs page: https://platform.openai.com/settings/profile?tab=api-keys\n",
        "- `PERPLEXITY_API_KEY` - used to search up-to-date information about the question. Get one from https://www.perplexity.ai/settings/api\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-9qnfxffRmm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have set these in the sidebar to the left, by pressing the key icon.\n",
        "from google.colab import userdata\n",
        "METACULUS_TOKEN = userdata.get('METACULUS_TOKEN')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "PERPLEXITY_API_KEY = userdata.get('PERPLEXITY_API_KEY')"
      ],
      "metadata": {
        "id": "MJJ_BYcHbVkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChatGPT Prompt\n",
        "\n",
        "You can change the prompt below to experiment. Key parameters that you can include in your prompt are:\n",
        "\n",
        "*   `{title}` The question itself\n",
        "*   `{summary_report}` A up to date news compliation generated from Perplexity\n",
        "*   `{background}` The background section of the Metaculus question. This comes from the `description` field on the question\n",
        "*   `{fine_print}` The fine print section of the question\n",
        "*   `{today}` Today's date. Remember that your bot doesn't know the date unless you tell it explicitly!\n",
        "\n",
        "\n",
        "**IMPORTANT**: As you experiment with changing the prompt, be aware that the last number output by GPT will be used as the forecast probability. The last line in the template specifies that.\n"
      ],
      "metadata": {
        "id": "K1v6Sy5K-NJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "You are a professional forecaster interviewing for a job.\n",
        "The interviewer is also a professional forecaster, with a strong track record of\n",
        "accurate forecasts of the future. They will ask you a question, and your task is\n",
        "to provide the most accurate forecast you can. To do this, you evaluate past data\n",
        "and trends carefully, make use of comparison classes of similar events, take into\n",
        "account base rates about how past events unfolded, and outline the best reasons\n",
        "for and against any particular outcome. You know that great forecasters don't\n",
        "just forecast according to the \"vibe\" of the question and the considerations.\n",
        "Instead, they think about the question in a structured way, recording their\n",
        "reasoning as they go, and they always consider multiple perspectives that\n",
        "usually give different conclusions, which they reason about together.\n",
        "You can't know the future, and the interviewer knows that, so you do not need\n",
        "to hedge your uncertainty, you are simply trying to give the most accurate numbers\n",
        "that will be evaluated when the events later unfold.\n",
        "\n",
        "Your interview question is:\n",
        "{title}\n",
        "\n",
        "Your research assistant says:\n",
        "{summary_report}\n",
        "\n",
        "background:\n",
        "{background}\n",
        "\n",
        "fine_print:\n",
        "{fine_print}\n",
        "\n",
        "Today is {today}.\n",
        "\n",
        "You write your rationale and give your final answer as: \"Probability: ZZ%\", 0-100\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vNStT_eV8tLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some setup code\n",
        "\n",
        "This section sets up some simple helper code you can use to get data about forecasting questions and to submit a prediction"
      ],
      "metadata": {
        "id": "iDukuXArbgdm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HifodCwcGU0j",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -qU openai\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "AUTH_HEADERS = {\"headers\": {\"Authorization\": f\"Token {METACULUS_TOKEN}\"}}\n",
        "API_BASE_URL = \"https://www.metaculus.com/api2\"\n",
        "WARMUP_TOURNAMENT_ID = 3294\n",
        "SUBMIT_PREDICTION = False\n",
        "\n",
        "def find_number_before_percent(s):\n",
        "    # Use a regular expression to find all numbers followed by a '%'\n",
        "    matches = re.findall(r'(\\d+)%', s)\n",
        "    if matches:\n",
        "        # Return the last number found before a '%'\n",
        "        return int(matches[-1])\n",
        "    else:\n",
        "        # Return None if no number found\n",
        "        return None\n",
        "\n",
        "def post_question_comment(question_id, comment_text):\n",
        "    \"\"\"\n",
        "    Post a comment on the question page as the bot user.\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        f\"{API_BASE_URL}/comments/\",\n",
        "        json={\n",
        "            \"comment_text\": comment_text,\n",
        "            \"submit_type\": \"N\",\n",
        "            \"include_latest_prediction\": True,\n",
        "            \"question\": question_id,\n",
        "        },\n",
        "        **AUTH_HEADERS,\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "\n",
        "def post_question_prediction(question_id, prediction_percentage):\n",
        "    \"\"\"\n",
        "    Post a prediction value (between 1 and 100) on the question.\n",
        "    \"\"\"\n",
        "    url = f\"{API_BASE_URL}/questions/{question_id}/predict/\"\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        json={\"prediction\": float(prediction_percentage) / 100},\n",
        "        **AUTH_HEADERS,\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "\n",
        "\n",
        "def get_question_details(question_id):\n",
        "    \"\"\"\n",
        "    Get all details about a specific question.\n",
        "    \"\"\"\n",
        "    url = f\"{API_BASE_URL}/questions/{question_id}/\"\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        **AUTH_HEADERS,\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    return json.loads(response.content)\n",
        "\n",
        "def list_questions(tournament_id=WARMUP_TOURNAMENT_ID, offset=0, count=10):\n",
        "    \"\"\"\n",
        "    List (all details) {count} questions from the {tournament_id}\n",
        "    \"\"\"\n",
        "    url_qparams = {\n",
        "        \"limit\": count,\n",
        "        \"offset\": offset,\n",
        "        \"has_group\": \"false\",\n",
        "        \"order_by\": \"-activity\",\n",
        "        \"forecast_type\": \"binary\",\n",
        "        \"project\": tournament_id,\n",
        "        \"status\": \"open\",\n",
        "        \"type\": \"forecast\",\n",
        "        \"include_description\": \"true\",\n",
        "    }\n",
        "    url = f\"{API_BASE_URL}/questions/\"\n",
        "    response = requests.get(url, **AUTH_HEADERS, params=url_qparams)\n",
        "    response.raise_for_status()\n",
        "    data = json.loads(response.content)\n",
        "\n",
        "def call_perplexity(query):\n",
        "    url = \"https://api.perplexity.ai/chat/completions\"\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"authorization\": f\"Bearer {PERPLEXITY_API_KEY}\",\n",
        "        \"content-type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"llama-3-sonar-large-32k-chat\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "You are an assistant to a superforecaster.\n",
        "The superforecaster will give you a question they intend to forecast on.\n",
        "To be a great assistant, you generate a concise but detailed rundown of the most relevant news, including if the question would resolve Yes or No based on current information.\n",
        "You do not produce forecasts yourself.\n",
        "\"\"\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": query},\n",
        "        ],\n",
        "    }\n",
        "    response = requests.post(url=url, json=payload, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return content\n",
        "\n",
        "def get_gpt_prediction(question_details):\n",
        "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    title = question_details[\"title\"]\n",
        "    resolution_criteria = question_details[\"resolution_criteria\"]\n",
        "    background = question_details[\"description\"]\n",
        "    fine_print = question_details[\"fine_print\"]\n",
        "\n",
        "    # Comment this line to not use perplexity\n",
        "    summary_report = call_perplexity(title)\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": PROMPT_TEMPLATE.format(\n",
        "                title=title,\n",
        "                summary_report=summary_report,\n",
        "                today=today,\n",
        "                background=background,\n",
        "                fine_print=fine_print,\n",
        "            )\n",
        "        }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    gpt_text = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Regular expression to find the number following 'Probability: '\n",
        "    probability_match = find_number_before_percent(gpt_text)\n",
        "\n",
        "    # Extract the number if a match is found\n",
        "    probability = None\n",
        "    if probability_match:\n",
        "        probability = int(probability_match) # int(match.group(1))\n",
        "        print(f\"The extracted probability is: {probability}%\")\n",
        "        probability = min(max(probability, 1), 99) # To prevent extreme forecasts\n",
        "\n",
        "    return probability, summary_report, gpt_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT prediction and submitting a forecast\n",
        "\n",
        "This is an example of how you can use the helper functions from above."
      ],
      "metadata": {
        "id": "9WUvm1tVmMkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question_id = 25140\n",
        "question_details = get_question_details(question_id)\n",
        "# print(question_details)\n",
        "\n",
        "prediction, perplexity_result, gpt_result = get_gpt_prediction(question_details)\n",
        "print(\"GPT predicted: \", prediction, perplexity_result, gpt_result)\n",
        "\n",
        "\n",
        "if prediction is not None and SUBMIT_PREDICTION:\n",
        "    post_question_prediction(question_id, prediction)\n",
        "    comment = \"PERPLEXITY\\n\\n\" + perplexity_result + \"\\n\\n#########\\n\\n\" + \"GPT\\n\\n\" + gpt_result\n",
        "    post_question_comment(question_id, comment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbQ6dmk9gzfk",
        "outputId": "27e4cd80-7664-4105-9e45-43c7df28a361",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The extracted probability is: 25%\n",
            "GPT predicted:  25 Here's a concise rundown of the most relevant news to help the superforecaster with this question:\n",
            "\n",
            "**Current Situation:**\n",
            "\n",
            "* The 2023-24 respiratory virus season is ongoing in the US, with COVID-19, influenza, and Respiratory Syncytial Virus (RSV) circulating simultaneously.\n",
            "* According to the Centers for Disease Control and Prevention (CDC), the current weekly hospitalization rates for each virus are:\n",
            "\t+ COVID-19: 14.1 per 100,000 (as of February 11, 2023) [1]\n",
            "\t+ Influenza: 23.1 per 100,000 (as of February 11, 2023) [2]\n",
            "\t+ RSV: 2.4 per 100,000 (as of February 4, 2023) [3]\n",
            "* The combined peak for each virus has not yet occurred, as the rates are still increasing or plateauing.\n",
            "\n",
            "**Trends and Projections:**\n",
            "\n",
            "* The CDC's FluView report suggests that influenza activity is expected to continue for several more weeks, with the peak potentially occurring in late February or early March [2].\n",
            "* COVID-19 hospitalization rates have been increasing slowly over the past few weeks, but the rate of growth has slowed down [1].\n",
            "* RSV hospitalization rates have been declining slightly over the past two weeks, but it's unclear if this trend will continue [3].\n",
            "\n",
            "**Resolution Based on Current Information:**\n",
            "\n",
            "* Based on the current trends and projections, it's difficult to determine whether the maximum weekly rate of hospitalizations per 100,000 in the US will occur within four weeks of the combined peak for each of COVID, influenza, and RSV.\n",
            "* The answer to this question would likely be \"Unknown\" or \"Maybe\" at this point, as the peaks for each virus have not yet occurred, and the interactions between them are complex.\n",
            "\n",
            "Please let me know if you'd like me to gather more information or provide further context to help with this question ### Structured Analysis:\n",
            "\n",
            "**1. Overview and Context:**\n",
            "The central question is whether the maximum weekly rate of hospitalizations per 100,000 in the US will occur within four weeks of the combined peak for each of COVID, influenza, and RSV in the 2023-24 season. This involves predicting and understanding peak timelines for three separate viruses and their confluence.\n",
            "\n",
            "**2. Historical Data Assessments:**\n",
            "- **2022-23 Season Patterns:**\n",
            "  - RSV peaked first (week ending November 12, 2022).\n",
            "  - Influenza had its maximum rate during the week ending December 3, 2022.\n",
            "  - COVID peaked later (week ending December 31, 2022).\n",
            "  - Combined hospitalization saw a significant peak on December 3, 2022.\n",
            "\n",
            "**3. Current Season Situation:**\n",
            "- **Hospitalization Rates (as of February 2023):**\n",
            "  - COVID-19: 14.1 per 100,000\n",
            "  - Influenza: 23.1 per 100,000\n",
            "  - RSV: 2.4 per 100,000\n",
            "\n",
            "- **Projected Peak Periods:**\n",
            "  - Influenza: late February to early March 2024.\n",
            "  - COVID-19: slowly increasing with a potential delayed peak.\n",
            "  - RSV: slight decline but peaks are harder to predict.\n",
            "\n",
            "**4. Insights from CDC RESP-NET:**\n",
            "- Technological and monitoring improvements allow more precise predictions and tracking.\n",
            "- The “tripledemic” pattern seen in 2022-23 could be a template for 2023-24.\n",
            "\n",
            "**5. Contributing Factors for Prediction:**\n",
            "- **Synchronicity of Peaks:**\n",
            "  - Viruses can peak at different times causing a staggered but overlapping impact.\n",
            "  - Environmental factors and emerging virus variants can impact the timing of peaks.\n",
            "- **Interaction Dynamics:**\n",
            "  - Interaction among circulating viruses can influence hospital rates: a high rate of one might affect others.\n",
            "  - Increased vaccination rates and public health measures may impact the behavior differently for each virus.\n",
            "\n",
            "**6. For and Against Analysis:**\n",
            "- **For Prediction of Coinciding Peaks:**\n",
            "  - Past seasons show a strong overlap, increasing probability.\n",
            "  - Measures and virus behaviors tend to lead to similar outcomes.\n",
            "- **Against Prediction of Coinciding Peaks:**\n",
            "  - Variability in viral evolution, public health responses, and immunity levels.\n",
            "  - Slightly shifting peak patterns due to unique yearly factors like new variants, changing weather patterns, and public health measures (masking, social distancing).\n",
            "\n",
            "### Final Analysis and Calculation:\n",
            "\n",
            "Combining historical data trends, CDC's projections, and robust comparative analysis of contributing factors, I believe there’s a strong probability the combined peak will align within a four-week period, akin to the pattern from the previous season (2022-23).\n",
            "\n",
            "- **Historical Accuracy (2022-23):** Strong overlap within a 3-week period.\n",
            "- **Current Peaks and Projected Timeline:** Each virus is at or approaching high activity levels.\n",
            "- **Interaction Effect:** Epidemiological response and interactions among viruses usually peak around common response times.\n",
            "\n",
            "### Final Forecast:\n",
            "\n",
            "Taking all analyzed data into account:\n",
            "\n",
            "**Probability: 75%**\n",
            "\n",
            "**Rationale:**\n",
            "This estimate stems from observed historical trends (2022-23 “tripledemic”), supportive evidence from the CDC’s RESP-NET, and consideration of seasonal viral behavior patterns. The 25% uncertainty reflects potential unexpected variations in virus interactions or public health interventions.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}